{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 1,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pickle\\n\",\n",
    "    \"import spacy\\n\",\n",
    "    \"nlp = spacy.load('en_core_web_lg')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"1667 2231\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"train_set = None\\n\",\n",
    "    \"with open(\\\"train.pkl\\\", \\\"rb\\\") as fi:\\n\",\n",
    "    \"    train_set = pickle.load(fi)\\n\",\n",
    "    \"\\n\",\n",
    "    \"eval_set = None\\n\",\n",
    "    \"with open(\\\"eval.pkl\\\", \\\"rb\\\") as fi:\\n\",\n",
    "    \"    eval_set = pickle.load(fi)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print (len(train_set), len(eval_set))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 3,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import nltk\\n\",\n",
    "    \"from nltk.corpus import stopwords\\n\",\n",
    "    \"stops = stopwords.words(\\\"english\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 4,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def prepare(corpus):\\n\",\n",
    "    \"    dataset = []\\n\",\n",
    "    \"    for item, label in corpus:\\n\",\n",
    "    \"        nouns = []\\n\",\n",
    "    \"        verbs = []\\n\",\n",
    "    \"        nouns_verbs = []\\n\",\n",
    "    \"        words = [] \\n\",\n",
    "    \"        tokens = nlp(item)\\n\",\n",
    "    \"        for token in tokens:\\n\",\n",
    "    \"            text = token.text.lower()\\n\",\n",
    "    \"            lemma = token.lemma_\\n\",\n",
    "    \"            if text in stops or lemma in stops:\\n\",\n",
    "    \"                continue\\n\",\n",
    "    \"            tag = token.tag_\\n\",\n",
    "    \"            is_oov = token.is_oov\\n\",\n",
    "    \"            has_vector = token.has_vector\\n\",\n",
    "    \"            if not has_vector or is_oov:\\n\",\n",
    "    \"                continue\\n\",\n",
    "    \"            vector = token.vector\\n\",\n",
    "    \"            if tag.startswith(\\\"NN\\\"):\\n\",\n",
    "    \"                nouns.append(vector)\\n\",\n",
    "    \"                nouns_verbs.append(vector)\\n\",\n",
    "    \"            elif tag.startswith(\\\"VB\\\"):\\n\",\n",
    "    \"                verbs.append(vector)\\n\",\n",
    "    \"                nouns_verbs.append(vector)\\n\",\n",
    "    \"            words.append(vector)        \\n\",\n",
    "    \"        nouns = np.array(nouns)\\n\",\n",
    "    \"        nouns = np.mean(nouns, axis=0, keepdims=True)        \\n\",\n",
    "    \"        verbs = np.array(verbs)\\n\",\n",
    "    \"        verbs = np.mean(verbs, axis=0, keepdims=True)\\n\",\n",
    "    \"        nouns_verbs = np.array(nouns_verbs)\\n\",\n",
    "    \"        nouns_verbs = np.mean(nouns_verbs, axis=0, keepdims=True)\\n\",\n",
    "    \"        words = np.array(words)        \\n\",\n",
    "    \"        words = np.mean(words, axis=0, keepdims=True)\\n\",\n",
    "    \"        sample = {\\n\",\n",
    "    \"            \\\"nouns\\\": nouns if len(nouns.shape) > 1 else None,\\n\",\n",
    "    \"            \\\"verbs\\\": verbs if len(verbs.shape) > 1 else None,\\n\",\n",
    "    \"            \\\"words\\\": words if len(words.shape) > 1 else None,\\n\",\n",
    "    \"            \\\"nouns_verbs\\\": nouns_verbs if len(nouns_verbs.shape) > 1 else None,\\n\",\n",
    "    \"            \\\"label\\\": label\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"        dataset.append(sample)\\n\",\n",
    "    \"    return dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 5,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stderr\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"/Users/mohitshah/.local/share/virtualenvs/in-out-rWorBeNE/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\\n\",\n",
    "      \"  out=out, **kwargs)\\n\",\n",
    "      \"/Users/mohitshah/.local/share/virtualenvs/in-out-rWorBeNE/lib/python3.6/site-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\\n\",\n",
    "      \"  ret, rcount, out=ret, casting='unsafe', subok=False)\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"train_data = prepare(train_set)\\n\",\n",
    "    \"eval_data = prepare(eval_set)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 6,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def get_features(dataset, key=\\\"nouns\\\"):    \\n\",\n",
    "    \"    items = [(x[key], x[\\\"label\\\"]) for x in dataset if x[key] is not None]\\n\",\n",
    "    \"    x = [xx[0] for xx in items]\\n\",\n",
    "    \"    y = [xx[1] for xx in items]\\n\",\n",
    "    \"    x = np.array(x).squeeze()    \\n\",\n",
    "    \"    return x, y\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 7,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"nouns_train_x, nouns_train_y = get_features(train_data, \\\"nouns\\\")\\n\",\n",
    "    \"nouns_eval_x, nouns_eval_y = get_features(eval_data, \\\"nouns\\\")\\n\",\n",
    "    \"verbs_train_x, verbs_train_y = get_features(train_data, \\\"verbs\\\")\\n\",\n",
    "    \"verbs_eval_x, verbs_eval_y = get_features(eval_data, \\\"verbs\\\")\\n\",\n",
    "    \"nv_train_x, nv_train_y = get_features(train_data, \\\"nouns_verbs\\\")\\n\",\n",
    "    \"nv_eval_x, nv_eval_y = get_features(eval_data, \\\"nouns_verbs\\\")\\n\",\n",
    "    \"words_train_x, words_train_y = get_features(train_data, \\\"words\\\")\\n\",\n",
    "    \"words_eval_x, words_eval_y = get_features(eval_data, \\\"words\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 8,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.svm import OneClassSVM\\n\",\n",
    "    \"def train_classifier(train_x):\\n\",\n",
    "    \"    clf = OneClassSVM()\\n\",\n",
    "    \"    clf.fit(train_x)\\n\",\n",
    "    \"    return clf\\n\",\n",
    "    \"\\n\",\n",
    "    \"def get_predictions(clf, x):\\n\",\n",
    "    \"    return clf.predict(x)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 9,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"n_clf = train_classifier(nouns_train_x)\\n\",\n",
    "    \"v_clf = train_classifier(verbs_train_x)\\n\",\n",
    "    \"nv_clf = train_classifier(nv_train_x)\\n\",\n",
    "    \"w_clf = train_classifier(words_train_x)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 10,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"n_preds = get_predictions(n_clf, nouns_eval_x)\\n\",\n",
    "    \"v_preds = get_predictions(v_clf, verbs_eval_x)\\n\",\n",
    "    \"nv_preds = get_predictions(nv_clf, nv_eval_x)\\n\",\n",
    "    \"w_preds = get_predictions(w_clf, words_eval_x)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 11,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.metrics import classification_report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 12,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"             precision    recall  f1-score   support\\n\",\n",
    "      \"\\n\",\n",
    "      \"         -1       0.70      0.28      0.40      1253\\n\",\n",
    "      \"          1       0.41      0.81      0.54       765\\n\",\n",
    "      \"\\n\",\n",
    "      \"avg / total       0.59      0.48      0.45      2018\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"print (classification_report(n_preds, nouns_eval_y))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 13,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"             precision    recall  f1-score   support\\n\",\n",
    "      \"\\n\",\n",
    "      \"         -1       0.50      0.26      0.34       572\\n\",\n",
    "      \"          1       0.50      0.75      0.60       581\\n\",\n",
    "      \"\\n\",\n",
    "      \"avg / total       0.50      0.50      0.47      1153\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"print (classification_report(v_preds, verbs_eval_y))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 14,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"             precision    recall  f1-score   support\\n\",\n",
    "      \"\\n\",\n",
    "      \"         -1       0.64      0.25      0.35      1398\\n\",\n",
    "      \"          1       0.36      0.75      0.49       780\\n\",\n",
    "      \"\\n\",\n",
    "      \"avg / total       0.54      0.43      0.40      2178\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"print (classification_report(nv_preds, nv_eval_y))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 15,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"             precision    recall  f1-score   support\\n\",\n",
    "      \"\\n\",\n",
    "      \"         -1       0.58      0.24      0.33      1373\\n\",\n",
    "      \"          1       0.37      0.72      0.49       839\\n\",\n",
    "      \"\\n\",\n",
    "      \"avg / total       0.50      0.42      0.39      2212\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"print (classification_report(w_preds, words_eval_y))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 16,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"             precision    recall  f1-score   support\\n\",\n",
    "      \"\\n\",\n",
    "      \"          0       0.39      0.13      0.19       498\\n\",\n",
    "      \"          1       0.77      0.93      0.84      1520\\n\",\n",
    "      \"\\n\",\n",
    "      \"avg / total       0.67      0.73      0.68      2018\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"norm = np.linalg.norm(nouns_train_x, 2, axis=1).reshape(-1, 1)\\n\",\n",
    "    \"n_t_x = nouns_train_x/norm\\n\",\n",
    "    \"norm = np.linalg.norm(nouns_eval_x, 2, axis=1).reshape(-1, 1)\\n\",\n",
    "    \"n_e_x = nouns_eval_x/norm\\n\",\n",
    "    \"sims = np.dot(n_e_x, n_t_x.T)\\n\",\n",
    "    \"max_sims = np.max(sims, axis=1)\\n\",\n",
    "    \"preds = [int(x > 0.5) for x in max_sims]\\n\",\n",
    "    \"truth = [int(x > 0) for x in nouns_eval_y]\\n\",\n",
    "    \"print (classification_report(truth, preds))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 17,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"             precision    recall  f1-score   support\\n\",\n",
    "      \"\\n\",\n",
    "      \"          0       0.28      0.85      0.42       556\\n\",\n",
    "      \"          1       0.83      0.26      0.39      1656\\n\",\n",
    "      \"\\n\",\n",
    "      \"avg / total       0.69      0.41      0.40      2212\\n\",\n",
    "      \"\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"norm = np.linalg.norm(words_train_x, 2, axis=1).reshape(-1, 1)\\n\",\n",
    "    \"n_t_x = words_train_x/norm\\n\",\n",
    "    \"norm = np.linalg.norm(words_eval_x, 2, axis=1).reshape(-1, 1)\\n\",\n",
    "    \"n_e_x = words_eval_x/norm\\n\",\n",
    "    \"sims = np.dot(n_e_x, n_t_x.T)\\n\",\n",
    "    \"max_sims = np.max(sims, axis=1)\\n\",\n",
    "    \"preds = [int(x > 0.85) for x in max_sims]\\n\",\n",
    "    \"truth = [int(x > 0) for x in words_eval_y]\\n\",\n",
    "    \"print (classification_report(truth, preds))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.6.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
